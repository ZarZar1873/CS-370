{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Augmenting training set images...\n",
      "0 % complete\n",
      "5 % complete\n",
      "10 % complete\n",
      "15 % complete\n",
      "20 % complete\n",
      "25 % complete\n",
      "30 % complete\n",
      "35 % complete\n",
      "40 % complete\n",
      "45 % complete\n",
      "50 % complete\n",
      "55 % complete\n",
      "60 % complete\n",
      "65 % complete\n",
      "70 % complete\n",
      "75 % complete\n",
      "80 % complete\n",
      "85 % complete\n",
      "90 % complete\n",
      "95 % complete\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10  \n",
    "from keras.utils import np_utils  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten \n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D  \n",
    "from keras.optimizers import SGD, Adam, RMSprop  \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy  as np   \n",
    "\n",
    "# For solving CERTIFICATE_VERIFY_FAILED error when downloading CIFAR10\n",
    "# From user Denise Mak posted on stack overflow\n",
    "# url: https://stackoverflow.com/questions/69687794/unable-to-manually-load-cifar10-dataset\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels \n",
    "IMG_CHANNELS = 3 \n",
    "IMG_ROWS = 32  \n",
    "IMG_COLS = 32  \n",
    "\n",
    "#constant  \n",
    "BATCH_SIZE = 128  \n",
    "NB_EPOCH = 20  \n",
    "NB_CLASSES = 10  \n",
    "VERBOSE = 1  \n",
    "VALIDATION_SPLIT = 0.2  \n",
    "OPTIM = RMSprop()  \n",
    "NUM_TO_AUGMENT=5\n",
    "\n",
    "#load dataset  \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()  \n",
    "print('X_train shape:', X_train.shape)  \n",
    "print(X_train.shape[0], 'train samples')  \n",
    "print(X_test.shape[0], 'test samples') \n",
    "\n",
    "# augumenting \n",
    "print(\"Augmenting training set images...\")\n",
    "datagen = ImageDataGenerator( \n",
    "    rotation_range=40, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest')\n",
    "\n",
    "xtas, ytas = [], [] \n",
    "for i in range(X_train.shape[0]): \n",
    "    num_aug = 0 \n",
    "    if (i % 2500) == 0:\n",
    "        print(round((i / X_train.shape[0]) * 100), '% complete')\n",
    "    x = X_train[i] # (3, 32, 32) \n",
    "    x = x.reshape((1,) + x.shape) # (1, 3, 32, 32) \n",
    "    \n",
    "    for x_aug in datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix='cifar', save_format='jpeg'): \n",
    "        if num_aug >= NUM_TO_AUGMENT: \n",
    "            break \n",
    "        xtas.append(x_aug[0]) \n",
    "        num_aug += 1\n",
    "\n",
    "# one-hot encoding and normalize the images \n",
    "#\n",
    "# convert to categorical  \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)  \n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)  \n",
    "\n",
    "# float and normalization  \n",
    "X_train = X_train.astype('float32')  \n",
    "X_test = X_test.astype('float32')  \n",
    "X_train /= 255  \n",
    "X_test /= 255 \n",
    "\n",
    "# net will learn 32 convolutional filters, each with a 3x3 size. \n",
    "# max-pooling operation with pool size 2x2 and a dropout at 25% \n",
    "#\n",
    "# network \n",
    "model = Sequential()  \n",
    "model.add(Conv2D(32, (3, 3), padding='same',  \n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))  \n",
    "model.add(Activation('relu'))  \n",
    "model.add(Conv2D(32, (3, 3), padding='same'))  \n",
    "model.add(Activation('relu'))  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Conv2D(64, (3, 3), padding='same'))  \n",
    "model.add(Activation('relu'))  \n",
    "model.add(Conv2D(64, (3, 3), padding='same'))    \n",
    "model.add(Activation('relu'))  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Flatten())  \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(NB_CLASSES))  \n",
    "model.add(Activation('softmax')) \n",
    "model.summary() \n",
    "\n",
    "# After defining the network, train the model.  \n",
    "# Split the data into validation, training, and testing sets.  \n",
    "# Training is used to build model, validation is used to select \n",
    "# the best performing approach, the test set is to check the performance \n",
    "# of the best model on fresh unseen data \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=20, verbose=1, callbacks=[<keras.ca..., steps_per_epoch=390)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "390/390 [==============================] - 115s 295ms/step - loss: 1.9462 - accuracy: 0.2913\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 116s 298ms/step - loss: 1.6666 - accuracy: 0.3971\n",
      "Epoch 3/20\n",
      "390/390 [==============================] - 118s 301ms/step - loss: 1.5446 - accuracy: 0.4441\n",
      "Epoch 4/20\n",
      "390/390 [==============================] - 113s 290ms/step - loss: 1.4533 - accuracy: 0.4768\n",
      "Epoch 5/20\n",
      "390/390 [==============================] - 120s 307ms/step - loss: 1.3928 - accuracy: 0.5024\n",
      "Epoch 6/20\n",
      "390/390 [==============================] - 114s 292ms/step - loss: 1.3504 - accuracy: 0.5180\n",
      "Epoch 7/20\n",
      "390/390 [==============================] - 114s 293ms/step - loss: 1.3116 - accuracy: 0.5329\n",
      "Epoch 8/20\n",
      "390/390 [==============================] - 119s 306ms/step - loss: 1.2787 - accuracy: 0.5474\n",
      "Epoch 9/20\n",
      "390/390 [==============================] - 114s 293ms/step - loss: 1.2583 - accuracy: 0.5546\n",
      "Epoch 10/20\n",
      "390/390 [==============================] - 120s 309ms/step - loss: 1.2393 - accuracy: 0.5632\n",
      "Epoch 11/20\n",
      "390/390 [==============================] - 116s 297ms/step - loss: 1.2234 - accuracy: 0.5669\n",
      "Epoch 12/20\n",
      "390/390 [==============================] - 115s 294ms/step - loss: 1.2136 - accuracy: 0.5719\n",
      "Epoch 13/20\n",
      "390/390 [==============================] - 121s 309ms/step - loss: 1.2054 - accuracy: 0.5816\n",
      "Epoch 14/20\n",
      "390/390 [==============================] - 116s 298ms/step - loss: 1.1997 - accuracy: 0.5803\n",
      "Epoch 15/20\n",
      "390/390 [==============================] - 118s 303ms/step - loss: 1.1917 - accuracy: 0.5865\n",
      "Epoch 16/20\n",
      "390/390 [==============================] - 118s 303ms/step - loss: 1.1799 - accuracy: 0.5878\n",
      "Epoch 17/20\n",
      "266/390 [===================>..........] - ETA: 37s - loss: 1.1781 - accuracy: 0.5916"
     ]
    }
   ],
   "source": [
    "#fit the dataget \n",
    "datagen.fit(X_train)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "\n",
    "#checkpoints\n",
    "checkpoint_filepath = 'keras_check'\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# train  \n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, \n",
    "                                           batch_size=BATCH_SIZE), \n",
    "                              samples_per_epoch=X_train.shape[0], \n",
    "                              epochs=NB_EPOCH, \n",
    "                              verbose=VERBOSE,\n",
    "                              callbacks = [cp_callback]) \n",
    "score = model.evaluate(X_test, Y_test, \n",
    "                       batch_size=BATCH_SIZE, \n",
    "                       verbose=VERBOSE) \n",
    "print(\"Test score:\", score[0]) \n",
    "print('Test accuracy:', score[1]) \n",
    "\n",
    "# Save the architecture of the deep network \n",
    "#\n",
    "#save model  \n",
    "model_json = model.to_json()  \n",
    "open('cifar10_architecture.json', 'w').write(model_json)  \n",
    "# And the weights learned by our deep network on the training \n",
    "model.save_weights('cifar10_weights.h5', overwrite=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of ethical and privacy implications revolving around image recognition AI. There can be unethical bias if the data being used to train the AI is biased for or against a group of its labels. There are concerns about where the training data comes from and the ethics of using another persons work to train something you claim as yours. There are concerns on the privacy of using an AI to train by trolling through images on the internet of people that have not consented to being a part of the training data. With the model that I created, it currently does not have any of those issues since the data is public it is not subject to privacy concerns, and since the model only differentiates between things like planes and cats it does not have really any ethical concerns beyond ensuring that the data does not contain any bias like giving favor to one group over another or excluding a group entirely.\n",
    "\n",
    "Refernces B. C. Stahl and D. Wright, \"Ethics and Privacy in AI and Big Data: Implementing Responsible Research and Innovation,\" in IEEE Security & Privacy, vol. 16, no. 3, pp. 26-33, May/June 2018, doi: 10.1109/MSP.2018.2701164. keywords: {Artificial intelligence;Ethics;Big Data;Data protection;artificial intelligence;smart information systems;ethics;responsible research and innovation;Human Brain Project;security;AI Ethics},"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
